nohup: ignoring input
/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Command Line Args:   --config config_dfnet_dronerace.txt
Config File (config_dfnet_dronerace.txt):
  model_name:        dfnet
  basedir:           ../logs/dronerace
  expname:           nerfh
  datadir:           ../data/Cambridge/DroneRace
  dataset_type:      Cambridge
  trainskip:         2
  testskip:          1
  df:                2
  load_pose_avg_stats:False
  NeRFH:             True
  epochs:            2000
  encode_hist:       True
  tinyimg:           True
  DFNet:             True
  tripletloss:       True
  featurenet_batch_size:4
  random_view_synthesis:True
  rvs_refresh_rate:  20
  rvs_trans:         3
  rvs_rotation:      7.5
  d_max:             1
Defaults:
  --fff:             1
  --places365_model_path:
  --reduce_embedding:-1
  --epochToMaxFreq:  -1
  --train_local_nerf:-1
  --i_eval:          20
  --netdepth:        8
  --netwidth:        128
  --netdepth_fine:   8
  --netwidth_fine:   128
  --N_rand:          1536
  --lrate:           0.0005
  --lrate_decay:     250
  --chunk:           32768
  --netchunk:        65536
  --N_vocab:         1000
  --hist_bin:        10
  --in_channels_a:   50
  --in_channels_t:   20
  --N_samples:       64
  --N_importance:    64
  --perturb:         1.0
  --i_embed:         0
  --multires:        10
  --multires_views:  4
  --raw_noise_std:   0.0
  --render_factor:   0
  --tinyscale:       4.0
  --pose_only:       1
  --learning_rate:   0.0001
  --batch_size:      1
  --pretrain_model_path:
  --combine_loss_w:  [1, 1, 1]
  --patience:        [200, 50]
  --resize_factor:   2
  --dropout:         0.5
  --val_batch_size:  1
  --mesh_grid_size:  80
  --precrop_iters:   0
  --precrop_frac:    0.5
  --triplet_margin:  1.0
  --factor:          8
  --llffhold:        8
  --i_print:         1
  --i_img:           500
  --i_weights:       200
  --i_testset:       200
  --i_video:         50000

NEAR FAR 0.0 10.0
Found ckpts ['../logs/dronerace/nerfh/000200.tar', '../logs/dronerace/nerfh/000400.tar', '../logs/dronerace/nerfh/000600.tar']
Reloading from ../logs/dronerace/nerfh/000600.tar
Not ndc!
Begin
TRAIN views are [  0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34
  36  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70
  72  74  76  78  80  82  84  86  88  90  92  94  96  98 100 102 104 106
 108 110 112 114 116 118 120 122 124 126 128 130 132 134 136 138 140 142
 144 146 148 150 152 154 156 158 160 162 164 166 168 170 172 174 176 178
 180 182 184 186 188 190 192 194 196 198 200]
TEST views are [   0    1    2 ... 2998 2999 3000]
VAL views are [   0    1    2 ... 2998 2999 3000]
/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torch/__init__.py:1264: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)
  _C._set_default_tensor_type(t)
renders 0/total 101
DEBUG: Input tensor shape: torch.Size([65536, 790])
DEBUG: Expected xyz: 63
DEBUG: Expected dir: 27
DEBUG: Expected a: 50
DEBUG: Expected t: 20
DEBUG: Has hist_bin: False
DEBUG: Calculated actual_xyz: 63, actual_dir_a: 77, actual_t: 20
DEBUG: Sum of calculated dimensions: 160
Traceback (most recent call last):
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/run_feature.py", line 465, in <module>
    train()
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/run_feature.py", line 445, in train
    train_feature(args, train_dl, val_dl, test_dl, hwf, i_split, near, far)
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/run_feature.py", line 349, in train_feature
    targets, rgbs, poses, img_idxs = render_nerfw_imgs(args, train_dl, hwf, device, render_kwargs_test, world_setup_dict)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/feature/misc.py", line 231, in render_nerfw_imgs
    rgb, _, _, _ = render(int(H//args.tinyscale), int(W//args.tinyscale), focal/args.tinyscale, chunk=args.chunk, c2w=pose_nerf[0,:3,:4].to(device), retraw=True, img_idx=img_idx, **render_kwargs_test)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/rendering.py", line 399, in render
    all_ret = batchify_rays(rays, chunk, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/rendering.py", line 346, in batchify_rays
    ret = render_rays(rays_flat[i:i+chunk], **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/rendering.py", line 314, in render_rays
    raw = network_query_fn(pts, viewdirs, img_idxs, network_fine, 'fine', embedding_a, embedding_t, output_transient, test_time=test_time)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/nerfw.py", line 445, in <lambda>
    typ, embedding_a, embedding_t, output_transient, test_time : run_network_NeRFW(inputs, viewdirs, ts, network_fn,
                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/nerfw.py", line 92, in run_network_NeRFW
    out_chunks += [fn(torch.cat(embedded_inputs, 1), output_transient=output_transient)]
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/script/models/nerfw.py", line 337, in forward
    torch.split(x, [actual_xyz, actual_dir_a, actual_t], dim=-1)
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torch/functional.py", line 222, in split
    return tensor.split(split_size_or_sections, dim)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/md127/home/UFAD/m.tomadakis/projects/Active/DFNet/.venv/lib/python3.12/site-packages/torch/_tensor.py", line 1052, in split
    return torch._VF.split_with_sizes(self, split_size, dim)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: split_with_sizes expects split_sizes to sum exactly to 790 (input tensor's size at dimension -1), but got split_sizes=[63, 77, 20]
